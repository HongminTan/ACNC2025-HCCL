# 适配算法编排接口<a name="ZH-CN_TOPIC_0000001904666578"></a>

算法编排过程是根据框架传入的资源，调用平台层提供的接口下发各种Task，实现数据同步等操作。

算法编排接口定义如下：

```
virtual HcclResult Orchestrate(const OpParam& param, const AlgResourceResponse& algRes);
```

参数说明如下表所示：

<a name="table827101275518"></a>
<table><thead align="left"><tr id="row429121265517"><th class="cellrowborder" valign="top" width="28.65286528652865%" id="mcps1.1.4.1.1"><p id="p1329121214558"><a name="p1329121214558"></a><a name="p1329121214558"></a>参数</p>
</th>
<th class="cellrowborder" valign="top" width="13.661366136613662%" id="mcps1.1.4.1.2"><p id="p10230141454318"><a name="p10230141454318"></a><a name="p10230141454318"></a>输入/输出</p>
</th>
<th class="cellrowborder" valign="top" width="57.68576857685769%" id="mcps1.1.4.1.3"><p id="p83121275519"><a name="p83121275519"></a><a name="p83121275519"></a>说明</p>
</th>
</tr>
</thead>
<tbody><tr id="row18118485118"><td class="cellrowborder" valign="top" width="28.65286528652865%" headers="mcps1.1.4.1.1 "><p id="p11104837101311"><a name="p11104837101311"></a><a name="p11104837101311"></a>param</p>
</td>
<td class="cellrowborder" valign="top" width="13.661366136613662%" headers="mcps1.1.4.1.2 "><p id="p8103173701314"><a name="p8103173701314"></a><a name="p8103173701314"></a>输入</p>
</td>
<td class="cellrowborder" valign="top" width="57.68576857685769%" headers="mcps1.1.4.1.3 "><p id="p151038375137"><a name="p151038375137"></a><a name="p151038375137"></a>算子的入参，包括输入输出指针、数据量等信息。</p>
<p id="p821675172614"><a name="p821675172614"></a><a name="p821675172614"></a>OpParam数据结构的介绍可参见<a href="OpParam.md">OpParam</a>。</p>
</td>
</tr>
<tr id="row191899195459"><td class="cellrowborder" valign="top" width="28.65286528652865%" headers="mcps1.1.4.1.1 "><p id="p1721319238619"><a name="p1721319238619"></a><a name="p1721319238619"></a>algRes</p>
</td>
<td class="cellrowborder" valign="top" width="13.661366136613662%" headers="mcps1.1.4.1.2 "><p id="p191021937151315"><a name="p191021937151315"></a><a name="p191021937151315"></a>输入</p>
</td>
<td class="cellrowborder" valign="top" width="57.68576857685769%" headers="mcps1.1.4.1.3 "><p id="p3101437131315"><a name="p3101437131315"></a><a name="p3101437131315"></a>AlgResourceRequest对象，存储算法传给框架的资源。</p>
<p id="p8996419102917"><a name="p8996419102917"></a><a name="p8996419102917"></a>AlgResourceRequest数据结构的介绍可参见<a href="AlgResourceRequest.md">AlgResourceRequest</a>。</p>
</td>
</tr>
</tbody>
</table>


此处以SendExecutor来为例，简要介绍下Executor的编排逻辑实现，用户实现自己的Executor编排逻辑可以参考该实现，也可以自己重新组织代码逻辑。对应的文件位于：

src/domain/collective\_communication/algorithm/impl/coll\_executor/coll\_send\_receive/coll\_send\_executor.cc

Orchestrate是算法编排的入口：

```
HcclResult CollSendExecutor::Orchestrate(const OpParam& param, const AlgResourceResponse& algRes)
{
    HcclUs startut = TIME_NOW();
    tag_ = param.tag;
    algResResp_ = &algRes;
    // 组装流对象,用于后续进一步使用
    GetStreamInfo(algRes);
    HcclResult ret = HCCL_SUCCESS;
    if (GetWorkflowMode() != HcclWorkflowMode::HCCL_WORKFLOW_MODE_OP_BASE) {
        DeviceMem InputMem = algRes.paramInputMem;
        // 图模式下直接对应对应子通信域的算法
        ret = RunTemplate(param, InputMem);
    } else {
        // 单算子模式下,因为CCL内存大小有限,如果数据量比较大,需要切片进行循环发送
        ret = RunLoop(param, algRes);
    }
    CHK_PRT_RET(ret != HCCL_SUCCESS,
        HCCL_ERROR("[CollSendExecutor][Orchestrate]errNo[0x%016llx]send excutor kernel run failed",
            HCCL_ERROR_CODE(ret)), ret);
    HCCL_INFO("tag[%s] Send Excutor orchestrate success, take time [%lld]us.",
        param.tag.c_str(), DURATION_US(TIME_NOW() - startut));
    return HCCL_SUCCESS;
}
```

因为单算子模式的流程能覆盖图模式，接下来重点介绍下单算子模式的处理流程：

```
HcclResult CollSendExecutor::RunLoop(const OpParam &param, const AlgResourceResponse &algRes)
{
    HcclResult ret;
    u64 commInputSize = algRes.cclInputMem.size();
    u32 unitSize = SIZE_TABLE[param.DataDes.dataType];
    // 生成meta信息,该meta信息用于标记一组task,因为单算子模式下task可能会多次循环下发,
    // 第二轮开始的task可复用第一轮结构体,仅需要刷新部分数据,这样可以优化下发性能
    auto meta = HcclOpMetaInfo::GetOneForSend();
    u8 *curInputPtr = static_cast<u8 *>(param.inputPtr);
    CHK_PTR_NULL(curInputPtr);
    u64 inputOffset = 0;
    u64 countLeft = param.DataDes.count;
    while (countLeft > 0) {
        // 标记一组Task的开始,相同标记下会复用缓存的结构体
        CHK_RET(InitTask(dispatcher_, const_cast<Stream&>(param.stream), meta.isEnableCache, meta.GetCacheKey()));
        curInputPtr += inputOffset;
        HCCL_DEBUG("SendOutPlace:inputOffset[%llu]", inputOffset);
        // 计算本轮可以处理的数据量
        u64 curCount = ((countLeft * unitSize) > commInputSize) ? (commInputSize / unitSize) : countLeft;
        u64 curSize = curCount * unitSize; // 单位 byte
        HCCL_DEBUG("SendOutPlace:curInputPtr[%p], curCount[%llu], curSize[%llu]", curInputPtr, curCount, curSize);
        DeviceMem inCommMem(algRes.cclInputMem.ptr(), curSize);
        DeviceMem inMem(curInputPtr, curSize);
        // 将数据从输入内存拷贝到CCL input内存
        CHK_RET(HcclD2DMemcpyAsync(dispatcher_, inCommMem, inMem, const_cast<Stream&>(param.stream)));
        /* 记录指令信息用于一致性校验 */
        ret = RankConsistent::GetInstance().RecordOpPara(HcclCMDType::HCCL_CMD_SEND, param.tag, curCount,
            param.DataDes.dataType, commInputSize, 0, HCCL_WORLD_GROUP);
        CHK_PRT_RET(ret != HCCL_SUCCESS,
            HCCL_ERROR("errNo[0x%016llx] record CMD with parameter error", HCCL_ERROR_CODE(ret)), ret);
        // 执行子通信域内的算法
        ret = RunTemplate(param, inCommMem);
        CHK_PRT_RET(ret != HCCL_SUCCESS,
            HCCL_ERROR("errNo[0x%016llx] SendOutPlace: send error, tag[%s], ptr[%p], count[%llu], dataType[%d]",
            HCCL_ERROR_CODE(ret), param.tag.c_str(), curInputPtr, curCount, param.DataDes.dataType),
            ret);
        /* 记录指令信息用于一致性校验 */
        ret = RankConsistent::GetInstance().DelOpPara(param.tag);
        CHK_PRT_RET(ret != HCCL_SUCCESS,
            HCCL_ERROR("errNo[0x%016llx] delete CMD with parameters error. tag[%s]", HCCL_ERROR_CODE(ret),
            param.tag.c_str()), ret);
        CHK_PRT_RET((curCount == 0), HCCL_ERROR("In OP_BASE curCount is zero"), HCCL_E_PARA);
        countLeft -= curCount;
        inputOffset = curSize;
        // 加载InitTask函数到LaunchTask函数之间的Task
        CHK_RET(LaunchTask(dispatcher_, const_cast<Stream&>(param.stream)));
    }
    return HCCL_SUCCESS;
}
```

接下来介绍子通信域内算法的编排：

```
HcclResult CollSendExecutor::RunTemplate(const OpParam &param, DeviceMem &inputMem)
{
    // 获取子通信域
    SubCommInfo commInfo = GetSubCommInfo(COMM_COMBINE, 0);
    if (commInfo.links.size() == 0) {
        HCCL_ERROR("[CollSendExecutor]links size is 0");
    }
    // 获取所需的链路
    LINK transportLink = commInfo.links[0];
    // 生成子通信域算法对象,并执行
    SendReceive sendExecutor(dispatcher_, transportLink);
    sendExecutor.SendPrepare(inputMem, param.dstRank, param.stream);
    sendExecutor.RegisterProfiler(0, PROF_STAGE_0, HCCL_EXEC_STEP_NOT_SET, param.stream);
    sendExecutor.SendRunAsync();
    return HCCL_SUCCESS;
}
```

SendRunAsync的逻辑如下：

```
HcclResult SendReceive::SendRunAsync()
{
    if (!inputMem_) {
        HCCL_ERROR("[SendReceive][SendRunAsync]SendRunAsync inputmem is null");
        return HCCL_E_PTR;
    }
    CHK_SMART_PTR_NULL(transLink_);
    u64 sizePerRound = 0;
    u64 sizePerSlice = chunkSize_;
    u64 length = inputMem_.size();
    u64 offset = 0;
    for (u64 sizeResidue = length; sizeResidue > 0; sizeResidue -= sizePerRound) {
        // 发送同步信号
        HcclResult ret = transLink_->TxAck(stream_);
        CHK_PRT_RET(ret != HCCL_SUCCESS, HCCL_ERROR("[SendReceive][SendRunAsync]tx ack run failed"), ret);
        // 接收同步信号
        ret = transLink_->RxAck(stream_);
        CHK_PRT_RET(ret != HCCL_SUCCESS, HCCL_ERROR("[SendReceive][SendRunAsync]rx ack run failed"), ret);
        // 计算地址偏移及长度等
        offset += sizePerRound;
        sizePerRound = (sizeResidue > sizePerSlice) ? sizePerSlice : sizeResidue;
        void* localAddr = static_cast<u8 *>(inputMem_.ptr()) + offset;
        HCCL_DEBUG("tx async inputmem's offset[%llu] size[%llu]", offset, sizePerRound);
        // 发送数据
        ret = transLink_->TxAsync(UserMemType::OUTPUT_MEM, offset, localAddr, sizePerRound, stream_);
        CHK_PRT_RET(ret != HCCL_SUCCESS, HCCL_ERROR("[SendReceive][SendRunAsync]tx async offset[%llu] "\
            "size[%llu] failed", offset, sizePerRound), ret);
        ret = transLink_->RxAsync(UserMemType::OUTPUT_MEM, 0, nullptr, 0, stream_);
        CHK_PRT_RET(ret != HCCL_SUCCESS, HCCL_ERROR("[SendReceive][ReceiveRunAsync]tx async failed"), ret);
        // 接收同步信号
        ret = transLink_->RxWaitDone(stream_);
        CHK_PRT_RET(ret != HCCL_SUCCESS, HCCL_ERROR("[SendReceive][SendRunAsync]RxWaitDone failed"), ret);
        // 发送同步信号
        ret = transLink_->TxWaitDone(stream_);
        CHK_PRT_RET(ret != HCCL_SUCCESS, HCCL_ERROR("[SendReceive][SendRunAsync]TxWaitDone failed"), ret);
    }
    return HCCL_SUCCESS;
}
```

